# -*- coding: utf-8 -*-
"""commit_dl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cmCFrN3tpq3Pbgt-_LVSd8iQ2r2U-JI1
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/commit_analys/

import pandas as pd

signal_data = pd.read_csv("signal_ios_commits.csv")
firefox_data = pd.read_csv("firefox_ios_commits.csv")
wikipedia_data = pd.read_csv("wikipedia_ios_commits.csv")
lottie_data = pd.read_csv("lottie_ios_commits.csv")
brave_data = pd.read_csv("brave_ios_commits.csv")

import os
os.environ["WANDB_DISABLED"] = "true"

import xgboost as xgb
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score

def process_and_train_xgboost(dataset, max_features=500, test_size=0.3):
    """
    XGBoost ile commit mesajlarını eğit ve değerlendir.

    Parameters:
    - dataset (pd.DataFrame): İşlenecek veri.
    - max_features (int): TF-IDF için maksimum özellik sayısı.
    - test_size (float): Test verisi oranı.

    Returns:
    - metrics (dict): Accuracy, F1 score, Recall ve Precision metrikleri.
    - report (str): Classification raporu.
    - y_test (array): Gerçek etiketler.
    - y_pred (array): Tahmin edilen etiketler.
    """
    # Veri bölme
    X = dataset['Message']
    y = dataset['Refactor']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

    # TF-IDF vektörleştirme
    vectorizer = TfidfVectorizer(max_features=max_features)
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)

    # XGBoost için DMatrices
    dtrain = xgb.DMatrix(X_train_tfidf, label=y_train)
    dtest = xgb.DMatrix(X_test_tfidf, label=y_test)

    # Model parametreleri
    params = {
        'objective': 'binary:logistic',
        'max_depth': 6,
        'eta': 0.1,
        'eval_metric': 'logloss',
        'verbosity': 1
    }

    # Model eğitimi
    model = xgb.train(params, dtrain, num_boost_round=100)

    # Tahmin
    y_pred = (model.predict(dtest) > 0.5).astype(int)

    # Metrik hesaplama
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Classification raporu
    report = classification_report(y_test, y_pred)

    # Metrikleri döndür
    metrics = {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1
    }

    return metrics, report, y_test, y_pred

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

def basic_process_and_train(dataset, max_features=500, test_size=0.3):
    """
    Dataset'i işle, modeli eğit ve test sonuçlarını döndür.

    Parameters:
    - dataset (pd.DataFrame): İşlenecek veri.
    - max_features (int): TF-IDF için maksimum özellik sayısı.
    - test_size (float): Test verisi oranı.

    Returns:
    - report (str): Classification raporu.
    """

    # Veri bölme
    X = dataset['Message']
    y = dataset['Refactor']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

    # TF-IDF vektörleştirme
    vectorizer = TfidfVectorizer(max_features=max_features)
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)

    # Model eğitimi
    model = LogisticRegression()
    model.fit(X_train_tfidf, y_train)

    # Tahmin ve değerlendirme
    y_pred = model.predict(X_test_tfidf)
    report = classification_report(y_test, y_pred)

    #Confusion Matrix
    plot_confusion_matrix(y_test, y_pred)

    return report

import matplotlib.pyplot as plt
import seaborn as sns

def plot_confusion_matrix(y_test, y_pred, class_labels=["Non-Refactor", "Refactor"]):
    """
    Confusion Matrix'i çiz.

    Parameters:
    - y_test (array): Gerçek etiketler.
    - y_pred (array): Tahmin edilen etiketler.
    - class_labels (list): Sınıf isimleri.
    """
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')

    plt.show()

def evaluate_model(dataName, data):
  metrics, report, y_test, y_pred = process_and_train_xgboost(data)
  print("")
  print(f"---{dataName} Data Metrics---\n")
  print("Metrics: ", metrics)
  print("\nClassification Report:")
  print(report)

  # Confusion Matrix'i çiz
  plot_confusion_matrix(y_test, y_pred)

evaluate_model("Signal", signal_data)
evaluate_model("Firefox", firefox_data)
evaluate_model("Wikipedia", wikipedia_data)
evaluate_model("Lottie", lottie_data)
evaluate_model("Brave", brave_data)